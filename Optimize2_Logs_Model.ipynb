{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zenost317/testGit/blob/main/Optimize2_Logs_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "pGf1AemKJ5QI",
        "outputId": "5bd37325-913c-406a-dd71-edc8b6c24537"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8293a998-ddd9-44a2-bd31-e492c47afd89\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8293a998-ddd9-44a2-bd31-e492c47afd89\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving labeled_logs_1.csv to labeled_logs_1.csv\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Đọc dữ liệu từ file CSV\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZELruEhKV8pR",
        "outputId": "8c321163-7acb-46b6-c494-23b58ba346f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Các nhãn có trong dữ liệu: ['Normal' 'NOTE - all threads closed'\n",
            " 'NOTE - speaker changes state from On to Off'\n",
            " 'NOTE - speaker changes state from Off to On' 'WARNING - On disconnect'\n",
            " 'ERROR - start MPD failed' 'ERROR - delete message' 'ERROR - MPD problem'\n",
            " 'ERROR - config SIM, GSM error' 'ERROR - invalid checksum'\n",
            " 'ERROR - invalid message size' 'Note - message played done'\n",
            " 'ERROR - message download' 'ERROR - control amplifier']\n",
            "Mapping giữa nhãn và số sau khi sửa: {'ERROR - MPD problem': np.int64(0), 'ERROR - config SIM, GSM error': np.int64(1), 'ERROR - control amplifier': np.int64(2), 'ERROR - delete message': np.int64(3), 'ERROR - invalid checksum': np.int64(4), 'ERROR - invalid message size': np.int64(5), 'ERROR - message download': np.int64(6), 'ERROR - start MPD failed': np.int64(7), 'NOTE - all threads closed': np.int64(8), 'NOTE - speaker changes state from Off to On': np.int64(9), 'NOTE - speaker changes state from On to Off': np.int64(10), 'Normal': np.int64(11), 'Note - message played done': np.int64(12), 'WARNING - On disconnect': np.int64(13)}\n",
            "Dữ liệu đã được xử lý và lưu thành công!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Đọc file CSV\n",
        "df = pd.read_csv(\"labeled_logs.csv\")\n",
        "\n",
        "# Chuẩn hóa cột \"labels\" (loại bỏ khoảng trắng thừa)\n",
        "df[\"labels\"] = df[\"labels\"].str.strip()\n",
        "\n",
        "# Kiểm tra nhãn trong dữ liệu\n",
        "unique_labels = df[\"labels\"].unique()\n",
        "print(\"Các nhãn có trong dữ liệu:\", unique_labels)\n",
        "\n",
        "# Tìm và sửa lỗi nhãn không đúng\n",
        "for label in unique_labels:\n",
        "    if \"NormalERROR\" in label or \"ERRORNormal\" in label:\n",
        "        print(\"Nhãn có vấn đề:\", label)\n",
        "\n",
        "# Sửa lỗi nhãn bằng cách thay thế tất cả trường hợp lỗi\n",
        "df[\"labels\"] = df[\"labels\"].replace({\n",
        "    \"NormalERROR - SIM, GSM\": \"Normal\"\n",
        "})\n",
        "\n",
        "# Mã hóa nhãn bằng LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"label_encoded\"] = label_encoder.fit_transform(df[\"labels\"])\n",
        "\n",
        "# Kiểm tra ánh xạ sau khi sửa\n",
        "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "print(\"Mapping giữa nhãn và số sau khi sửa:\", label_mapping)\n",
        "\n",
        "# Lưu LabelEncoder để sử dụng sau này\n",
        "with open(\"label_encoder.pkl\", \"wb\") as f:\n",
        "    pickle.dump(label_encoder, f)\n",
        "\n",
        "# Xuất file CSV đã xử lý\n",
        "df.to_csv(\"processed_logs.csv\", index=False)\n",
        "\n",
        "print(\"Dữ liệu đã được xử lý và lưu thành công!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSjqV8KeMcRM",
        "outputId": "1bf49442-6193-4860-fb77-362f83dd9828"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Danh sách nhãn sau khi làm sạch: ['Normal' 'NOTE - all threads closed'\n",
            " 'NOTE - speaker changes state from On to Off'\n",
            " 'NOTE - speaker changes state from Off to On' 'WARNING - On disconnect'\n",
            " 'ERROR - start MPD failed' 'ERROR - delete message' 'ERROR - MPD problem'\n",
            " 'ERROR - config SIM, GSM error' 'ERROR - invalid checksum'\n",
            " 'ERROR - invalid message size' 'Note - message played done'\n",
            " 'ERROR - message download' 'ERROR - control amplifier']\n"
          ]
        }
      ],
      "source": [
        "# Sửa các nhãn có vấn đề\n",
        "df[\"labels\"] = df[\"labels\"].replace({\"NormalERROR - SIM, GSM\": \"Normal\"})  # Hoặc sửa theo đúng nhãn mong muốn\n",
        "\n",
        "# Đảm bảo tất cả nhãn đều hợp lệ\n",
        "df[\"labels\"] = df[\"labels\"].apply(lambda x: x.strip() if isinstance(x, str) else x)\n",
        "\n",
        "# Kiểm tra lại\n",
        "print(\"Danh sách nhãn sau khi làm sạch:\", df[\"labels\"].unique())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PF3pu48jliwf"
      },
      "source": [
        "**TOKENIZE DỮ LIỆU VÀ CHIA DỮ LIỆU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuIcp93SWQMx",
        "outputId": "8e236fdb-6505-49d6-89fa-baf53ab510bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Tên các cột trong DataFrame: ['logs', 'labels', 'label_encoded']\n",
            "Tổng số mẫu: 4820\n",
            "Số mẫu train: 3856\n",
            "Số mẫu test: 482\n",
            "Số mẫu val: 482\n"
          ]
        }
      ],
      "source": [
        "# Cài đặt thư viện cần thiết\n",
        "!pip install torch transformers datasets scikit-learn pandas\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from transformers import DistilBertTokenizer\n",
        "\n",
        "# Đọc file CSV\n",
        "df = pd.read_csv(\"processed_logs.csv\", encoding=\"utf-8\")\n",
        "\n",
        "# Kiểm tra các cột có trong DataFrame\n",
        "print(\"Tên các cột trong DataFrame:\", df.columns.tolist())\n",
        "\n",
        "# Kiểm tra nếu 'logs' không tồn tại thì báo lỗi\n",
        "if \"logs\" not in df.columns:\n",
        "    raise ValueError(\"Cột 'logs' không tồn tại trong file CSV! Kiểm tra lại tên cột.\")\n",
        "\n",
        "# Loại bỏ các dòng có giá trị NaN trong logs\n",
        "df = df.dropna(subset=[\"logs\"])\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "max_length = 128  # Độ dài tối đa của chuỗi token\n",
        "\n",
        "tokens = tokenizer(\n",
        "    df[\"logs\"].tolist(),  # Chuyển logs thành danh sách trước khi token hóa\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    max_length=max_length,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "# Dataset PyTorch\n",
        "class LogDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "# Kiểm tra xem 'label_encoded' có tồn tại không\n",
        "if \"label_encoded\" not in df.columns:\n",
        "    raise ValueError(\"Cột 'label_encoded' không tồn tại! Kiểm tra lại dữ liệu.\")\n",
        "\n",
        "# Chuyển nhãn thành tensor\n",
        "labels = torch.tensor(df[\"label_encoded\"].values, dtype=torch.long)\n",
        "\n",
        "# Tạo dataset\n",
        "dataset = LogDataset(tokens, labels)\n",
        "\n",
        "# Chia tập train/test (80/20)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = int(0.1 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# Tạo DataLoader\n",
        "batch_size = 16\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False) # Create val_loader\n",
        "\n",
        "\n",
        "# Kiểm tra số lượng mẫu\n",
        "print(f\"Tổng số mẫu: {len(dataset)}\")\n",
        "print(f\"Số mẫu train: {len(train_dataset)}\")\n",
        "print(f\"Số mẫu test: {len(test_dataset)}\")\n",
        "print(f\"Số mẫu val: {len(val_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMvPVN_gXVNC",
        "outputId": "52221b41-2c69-43c7-a06b-c50957f12380"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch transformers datasets scikit-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd0tThPIldCV"
      },
      "source": [
        "**CÀI ĐẶT CUDA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z45CVRPdXYSB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9985c6d4-190d-4596-b5a5-cd795b19dae9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sử dụng thiết bị: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import DistilBertForSequenceClassification\n",
        "\n",
        "# Kiểm tra GPU (nếu có)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Sử dụng thiết bị: {device}\")\n",
        "\n",
        "# Khởi tạo mô hình với DistilBERT\n",
        "num_labels = len(df[\"label_encoded\"].unique())  # Số nhãn đầu ra\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=num_labels)\n",
        "model.to(device)\n",
        "\n",
        "# Định nghĩa hàm mất mát và optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZDlF4YJPBYj"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, input_ids, attention_masks, labels):\n",
        "        self.input_ids = input_ids\n",
        "        self.attention_masks = attention_masks\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {\n",
        "            \"input_ids\": self.input_ids[idx],\n",
        "            \"attention_mask\": self.attention_masks[idx],\n",
        "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long)  # Dòng này gây cảnh báo\n",
        "        }\n",
        "\n",
        "        # Kiểm tra nếu labels chưa là tensor, thì chuyển đổi\n",
        "        label = self.labels[idx]\n",
        "        if not isinstance(label, torch.Tensor):\n",
        "            label = torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "        item[\"labels\"] = label  # Gán nhãn vào item\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbhGQ_dElZqR"
      },
      "source": [
        "**CẤU HÌNH TRAIN VÀ TIẾN HÀNH TRAIN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4WTjer6OMeM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fdf6006-916c-4566-8949-71c1937f7ff8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-1f5eb81ecb5e>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n"
          ]
        }
      ],
      "source": [
        "# Kiểm tra train_loader có tồn tại không\n",
        "assert 'train_loader' in globals(), \"train_loader chưa được khởi tạo!\"\n",
        "\n",
        "# Kiểm tra batch có đủ input_ids, attention_mask, labels\n",
        "sample_batch = next(iter(train_loader))\n",
        "assert \"input_ids\" in sample_batch and \"attention_mask\" in sample_batch and \"labels\" in sample_batch, \\\n",
        "    \"Batch không chứa đủ input_ids, attention_mask, labels!\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2uBZMmeXgAh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57f6f806-096b-41b6-a652-08362a1d9979"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/3:   0%|          | 0/241 [00:00<?, ?it/s]<ipython-input-37-1f5eb81ecb5e>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "Epoch 1/3: 100%|██████████| 241/241 [00:41<00:00,  5.81it/s, loss=0.00688]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/3:\n",
            "Train Loss: 0.4045\n",
            "Val Loss: 0.0222, Val Accuracy: 99.7925%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/3: 100%|██████████| 241/241 [00:41<00:00,  5.86it/s, loss=0.572]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2/3:\n",
            "Train Loss: 0.0356\n",
            "Val Loss: 0.1104, Val Accuracy: 98.5477%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/3: 100%|██████████| 241/241 [00:41<00:00,  5.78it/s, loss=0.00485]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3/3:\n",
            "Train Loss: 0.0288\n",
            "Val Loss: 0.0143, Val Accuracy: 99.7925%\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm  # Hiển thị tiến trình huấn luyện\n",
        "\n",
        "# Hàm tính độ chính xác\n",
        "def compute_accuracy(model, data_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Dự đoán nhãn\n",
        "            preds = torch.argmax(outputs.logits, dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    avg_loss = total_loss / len(data_loader)\n",
        "    accuracy = correct / total\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "# Số epoch huấn luyện\n",
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=True)\n",
        "    for batch in loop:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    # Tính loss & accuracy trên tập train\n",
        "    train_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # Tính loss & accuracy trên tập validation\n",
        "    val_loss, val_accuracy = compute_accuracy(model, val_loader)\n",
        "\n",
        "    print(f\"\\nEpoch {epoch+1}/{epochs}:\")\n",
        "    print(f\"Train Loss: {train_loss:.4f}\")\n",
        "    print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4%}\")\n",
        "    print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRAaVAAHTamn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0dde587-59f3-4178-ed70-5b3e6d07aeab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Mô hình và tokenizer đã được lưu vào thư mục: distilbert_log_classifier\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Tạo thư mục lưu mô hình\n",
        "model_dir = \"distilbert_log_classifier\"\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "# Lưu mô hình\n",
        "model.save_pretrained(model_dir)\n",
        "tokenizer.save_pretrained(model_dir)\n",
        "\n",
        "print(f\" Mô hình và tokenizer đã được lưu vào thư mục: {model_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMYg6KYfTf-2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a13632a7-64fd-4f04-ecb8-da473ba4636c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " LabelEncoder đã được lưu tại: distilbert_log_classifier/label_encoder.pkl\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# Lưu LabelEncoder\n",
        "label_encoder_path = os.path.join(model_dir, \"label_encoder.pkl\")\n",
        "with open(label_encoder_path, \"wb\") as f:\n",
        "    pickle.dump(label_encoder, f)\n",
        "\n",
        "print(f\" LabelEncoder đã được lưu tại: {label_encoder_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxuvSubMThdY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36c2ad60-c4be-4710-d446-568f452da39d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Danh sách tệp đã lưu:\n",
            "['vocab.txt', 'model.safetensors', 'tokenizer_config.json', 'label_encoder.pkl', 'config.json', 'special_tokens_map.json']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(\" Danh sách tệp đã lưu:\")\n",
        "print(os.listdir(model_dir))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX20g4jBUHbG"
      },
      "source": [
        "**TẢI LẠI MÔ HÌNH VÀ TOKENIZER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ie7Cx6BXTkoG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79ad31bb-8d2d-4ef6-8fc4-f242da1ef02e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Mô hình và tokenizer đã được tải thành công!\n"
          ]
        }
      ],
      "source": [
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "import torch\n",
        "import pickle\n",
        "\n",
        "# Định nghĩa đường dẫn mô hình đã lưu\n",
        "model_dir = \"distilbert_log_classifier\"\n",
        "\n",
        "# Tải mô hình & tokenizer\n",
        "model = DistilBertForSequenceClassification.from_pretrained(model_dir)\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(model_dir)\n",
        "\n",
        "# Đưa mô hình lên GPU nếu có\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(\" Mô hình và tokenizer đã được tải thành công!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBWyTX12UTNW"
      },
      "source": [
        "**TẢI LẠI LABEL ENCODER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhkFZjTCTvzO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6402f7fe-7dcf-4aff-90d3-48d2b1273ae2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " LabelEncoder đã được tải thành công!\n"
          ]
        }
      ],
      "source": [
        "# Tải LabelEncoder để giải mã nhãn\n",
        "label_encoder_path = f\"{model_dir}/label_encoder.pkl\"\n",
        "with open(label_encoder_path, \"rb\") as f:\n",
        "    label_encoder = pickle.load(f)\n",
        "\n",
        "print(\" LabelEncoder đã được tải thành công!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff8txBcxUbDf"
      },
      "source": [
        "**KIỂM TRA MÔ HÌNH VỚI 1 LOG**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HEc3kZAT1Vm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff7d8e18-f245-439f-bce8-aa470cf4547a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Log: System overheating detected. Shutting down in 5 seconds\n",
            "Cảnh báo dự đoán: Normal\n"
          ]
        }
      ],
      "source": [
        "log_message = \"System overheating detected. Shutting down in 5 seconds\"\n",
        "# Tokenize dữ liệu\n",
        "inputs = tokenizer(log_message, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "inputs = {key: val.to(device) for key, val in inputs.items()}  # Đưa lên GPU nếu có\n",
        "\n",
        "# Thực hiện suy luận\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    predicted_label = torch.argmax(outputs.logits, dim=1).cpu().item()\n",
        "\n",
        "# Giải mã nhãn từ số thành nội dung cảnh báo\n",
        "decoded_label = label_encoder.inverse_transform([predicted_label])[0]\n",
        "\n",
        "print(f\" Log: {log_message}\")\n",
        "print(f\"Cảnh báo dự đoán: {decoded_label}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRdlYWmOUgv3"
      },
      "source": [
        "**KIỂM TRA MÔ HÌNH VỚI NHIỀU LOG**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2yDUbiOT7Yu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "015044b7-5169-4bc5-e45a-ac73b7067bc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Log: Temperature sensor failure detected.\n",
            " Cảnh báo dự đoán: WARNING - On disconnect\n",
            "--------------------------------------------------\n",
            " Log: Unauthorized access attempt detected.\n",
            " Cảnh báo dự đoán: WARNING - On disconnect\n",
            "--------------------------------------------------\n",
            " Log: Battery voltage critically low.\n",
            " Cảnh báo dự đoán: Normal\n",
            "--------------------------------------------------\n",
            " Log: Network connection lost. Reconnecting...\n",
            " Cảnh báo dự đoán: Normal\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "log_samples = [\n",
        "    \"Temperature sensor failure detected.\",\n",
        "    \"Unauthorized access attempt detected.\",\n",
        "    \"Battery voltage critically low.\",\n",
        "    \"Network connection lost. Reconnecting...\"\n",
        "]\n",
        "\n",
        "for log in log_samples:\n",
        "    inputs = tokenizer(log, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    inputs = {key: val.to(device) for key, val in inputs.items()}  # Đưa lên GPU nếu có\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        predicted_label = torch.argmax(outputs.logits, dim=1).cpu().item()\n",
        "\n",
        "    # decoded_label = label_encoder.inverse_transform([predicted_label])[0]\n",
        "    decoded_label = label_encoder.classes_[predicted_label]\n",
        "\n",
        "    print(f\" Log: {log}\")\n",
        "    print(f\" Cảnh báo dự đoán: {decoded_label}\")\n",
        "    print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8SiSUyTB6Ok"
      },
      "source": [
        "**LƯU LẠI MÔ HÌNH TRAIN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2UPe3Lo_T6N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bc76886-9bb0-4a84-c786-fb89ac9e91e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
            "\n",
            "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n",
            "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7cd68a7ebfd0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7cd6ba3e47d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7cd6ba3776d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7cd6a07daf10>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7cd68b2f1b10>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7cd6a02dec50>, because it is not built.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Mô hình đã được chuyển sang định dạng TensorFlow và lưu tại: saved_model_distilbert\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFDistilBertForSequenceClassification\n",
        "\n",
        "# Tải lại mô hình từ thư mục đã lưu trước đó\n",
        "model = TFDistilBertForSequenceClassification.from_pretrained(\"distilbert_log_classifier\", from_pt=True)\n",
        "\n",
        "# Chuyển mô hình sang định dạng SavedModel (để có saved_model.pb)\n",
        "export_dir = \"saved_model_distilbert\"\n",
        "model.save_pretrained(export_dir, saved_model=True)\n",
        "\n",
        "print(f\" Mô hình đã được chuyển sang định dạng TensorFlow và lưu tại: {export_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHX5_7QgB1v9"
      },
      "source": [
        "**TỐI ƯU MÔ HÌNH**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UUDLBlZH50d"
      },
      "source": [
        "**Convert to TF lite**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9WLAAtbVAIV"
      },
      "source": [
        "**CHUYỂN MÔ HÌNH SANG TF**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEE0ubzhZjv8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaa74844-4787-401a-8d37-ffea6aa892f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Mô hình đã lưu thành công!\n",
            " Danh sách file trong saved_model_distilbert/saved_model: ['1']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Kiểm tra thư mục đã lưu mô hình\n",
        "export_dir = \"saved_model_distilbert/saved_model\"\n",
        "\n",
        "if os.path.exists(export_dir):\n",
        "    print(\" Mô hình đã lưu thành công!\")\n",
        "    print(f\" Danh sách file trong {export_dir}: {os.listdir(export_dir)}\")\n",
        "else:\n",
        "    print(\" Lưu mô hình thất bại! Hãy kiểm tra lại quá trình lưu mô hình.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxXJKp99dBOJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcf67311-0d26-4901-fdf0-afcda12c2c3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Chuyển đổi thành công! File đã lưu.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load mô hình đã huấn luyện\n",
        "model = tf.keras.models.load_model(\"saved_model_distilbert/saved_model/1/\")\n",
        "\n",
        "# Chuyển đổi sang TFLite\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"saved_model_distilbert/saved_model/1/\")\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Lưu file .tflite\n",
        "with open(\"distilbert_log_classifier.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\" Chuyển đổi thành công! File đã lưu.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CA0PpWHEfCeZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39994ac3-58b2-4e87-926d-f8ded79474f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'name': 'serving_default_attention_mask:0', 'index': 0, 'shape': array([  1, 128], dtype=int32), 'shape_signature': array([  1, 128], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_input_ids:0', 'index': 1, 'shape': array([  1, 128], dtype=int32), 'shape_signature': array([  1, 128], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
          ]
        }
      ],
      "source": [
        "print(input_details)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_cCyKamccOJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fafde76-4a28-483f-b527-dda20c3e743a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log: Close all threads\n",
            "Predicted Label: 11\n"
          ]
        }
      ],
      "source": [
        "import tensorflow.lite as tflite\n",
        "import numpy as np\n",
        "from transformers import DistilBertTokenizer\n",
        "\n",
        "# Load tokenizer giống như lúc train\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "# Load model\n",
        "interpreter = tflite.Interpreter(model_path=\"distilbert_log_classifier.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Lấy thông tin tensor input/output\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Chuyển đổi câu log thành tensor (chỉ lấy token đầu tiên)\n",
        "test_log = \"Close all threads\"\n",
        "tokens = tokenizer.encode(test_log, truncation=True)\n",
        "\n",
        "# Chỉ lấy 1 token đầu tiên để phù hợp shape [1, 1]\n",
        "first_token = tokens[0] if len(tokens) > 0 else 0\n",
        "\n",
        "# Đảm bảo đúng shape [1, 1]\n",
        "input_ids = np.array([[first_token]], dtype=np.int64)\n",
        "attention_mask = np.array([[1]], dtype=np.int64)\n",
        "\n",
        "# Set input tensor\n",
        "interpreter.set_tensor(input_details[0]['index'], attention_mask)  # attention mask\n",
        "interpreter.set_tensor(input_details[1]['index'], input_ids)  # input IDs\n",
        "\n",
        "# Chạy mô hình\n",
        "interpreter.invoke()\n",
        "\n",
        "# Lấy kết quả\n",
        "output = interpreter.get_tensor(output_details[0]['index'])\n",
        "predicted_label = np.argmax(output)\n",
        "\n",
        "print(f\"Log: {test_log}\")\n",
        "print(f\"Predicted Label: {predicted_label}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOhU2__CdJms"
      },
      "source": [
        "*italicised text*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPeImvu3dJ26"
      },
      "source": [
        "**XỬ LÝ ĐẦU VÀO MÔ HÌNH CHO QUÁ TRÌNH PTQ**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-pjUtaDeZV7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7bc370a-d335-4a32-8525-180bd2490829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7cd68b5f0790>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7cd6a0772810>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7cd68b18a1d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7cd6ba360a90>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7cd69bf05d50>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7cd6a01119d0>, because it is not built.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mô hình đã lưu với input cố định tại saved_model_distilbert_fixed\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load lại mô hình từ SavedModel\n",
        "model = tf.keras.models.load_model(\"saved_model_distilbert/saved_model/1\", compile=False)\n",
        "\n",
        "# Chuyển mô hình về dạng `tf.function` để cố định input shape\n",
        "@tf.function(input_signature=[\n",
        "    tf.TensorSpec(shape=[1, 128], dtype=tf.int32, name=\"input_ids\"),\n",
        "    tf.TensorSpec(shape=[1, 128], dtype=tf.int32, name=\"attention_mask\"),\n",
        "])\n",
        "def serving_fn(input_ids, attention_mask):\n",
        "    outputs = model({\"input_ids\": input_ids, \"attention_mask\": attention_mask})\n",
        "    logits = outputs[\"logits\"]  # Truy cập logits từ dictionary\n",
        "    return {\"logits\": tf.identity(logits, name=\"logits\")}  # Đảm bảo output là tf.Tensor\n",
        "\n",
        "# Lưu mô hình mới với input cố định\n",
        "fixed_model_dir = \"saved_model_distilbert_fixed\"\n",
        "tf.saved_model.save(model, fixed_model_dir, signatures={\"serving_default\": serving_fn})\n",
        "\n",
        "print(f\"Mô hình đã lưu với input cố định tại {fixed_model_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQVUDB3nghYc"
      },
      "source": [
        "**THỰC HIỆN PTQ INT8**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8uQfzQOeewz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa1894a0-472b-44c0-ee24-c680fd575bba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Chuyển đổi thành công!\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Load mô hình đã sửa\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"saved_model_distilbert_fixed\")\n",
        "\n",
        "# Bật lượng tử hóa trọng số (INT8)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "\n",
        "# Sử dụng tập dữ liệu đại diện để giúp lượng tử hóa\n",
        "def representative_dataset_gen():\n",
        "    for _ in range(100):\n",
        "        input_ids = np.random.randint(0, 30522, size=(1, 128), dtype=np.int32)\n",
        "        attention_mask = np.ones((1, 128), dtype=np.int32)\n",
        "        yield [input_ids, attention_mask]  # Trả về tuple thay vì dictionary\n",
        "\n",
        "converter.representative_dataset = representative_dataset_gen\n",
        "\n",
        "# Cấu hình kiểu dữ liệu đầu vào và đầu ra của mô hình\n",
        "converter.inference_input_type = tf.int8   # Đầu vào INT8\n",
        "converter.inference_output_type = tf.int8  # Đầu ra INT8\n",
        "\n",
        "# Chuyển đổi mô hình sang TFLite\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Lưu mô hình mới\n",
        "with open(\"distilbert_log_classifier_int8.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\" Chuyển đổi thành công!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lc1GrX6cfaRb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bea4a59-0d79-44bb-f1ba-f6c447f6c525"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thông tin đầu vào: [{'name': 'serving_default_attention_mask:0', 'index': 0, 'shape': array([  1, 128], dtype=int32), 'shape_signature': array([  1, 128], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_input_ids:0', 'index': 1, 'shape': array([  1, 128], dtype=int32), 'shape_signature': array([  1, 128], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
            "Thông tin đầu ra: [{'name': 'StatefulPartitionedCall:0', 'index': 389, 'shape': array([ 1, 14], dtype=int32), 'shape_signature': array([ 1, 14], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.033204950392246246, -27), 'quantization_parameters': {'scales': array([0.03320495], dtype=float32), 'zero_points': array([-27], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
            "Kết quả đầu ra (logits float32): [[ 0.36525446 -3.1212654  -2.5235763  -2.7892158  -0.76371384 -1.7266574\n",
            "  -1.959092   -2.9552405  -2.0919118  -1.959092   -2.722806    4.9807425\n",
            "  -1.8926822   2.1251168 ]]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Load mô hình TFLite INT8\n",
        "interpreter = tf.lite.Interpreter(model_path=\"distilbert_log_classifier_int8.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Lấy thông tin tensor đầu vào & đầu ra\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "print(\"Thông tin đầu vào:\", input_details)\n",
        "print(\"Thông tin đầu ra:\", output_details)\n",
        "\n",
        "# Tạo dữ liệu test (để nguyên dtype int32)\n",
        "input_ids = np.random.randint(0, 30522, size=(1, 128), dtype=np.int32)\n",
        "attention_mask = np.ones((1, 128), dtype=np.int32)\n",
        "\n",
        "# Đưa dữ liệu vào mô hình (KHÔNG CHUYỂN SANG int8)\n",
        "interpreter.set_tensor(input_details[0][\"index\"], attention_mask)\n",
        "interpreter.set_tensor(input_details[1][\"index\"], input_ids)\n",
        "\n",
        "# Chạy mô hình\n",
        "interpreter.invoke()\n",
        "\n",
        "# Lấy kết quả đầu ra & giải lượng tử hóa\n",
        "output_scale, output_zero_point = output_details[0]['quantization']\n",
        "output_data_q = interpreter.get_tensor(output_details[0][\"index\"])\n",
        "output_data = (output_data_q.astype(np.float32) - output_zero_point) * output_scale\n",
        "\n",
        "print(\"Kết quả đầu ra (logits float32):\", output_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rjTuUlbYFcC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4974172-eaa0-47d4-a5b5-d9a8c45ea5bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nhãn dự đoán: [11]\n"
          ]
        }
      ],
      "source": [
        "predicted_label = np.argmax(output_data, axis=-1)\n",
        "print(\"Nhãn dự đoán:\", predicted_label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0pyaaplZD_j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51fd4a54-b6a6-487f-b9fc-acc73821d220"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Kích thước mô hình gốc: 260.41 MB\n",
            " Kích thước INT8: 64.74 MB\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def get_dir_size(path):\n",
        "    total_size = 0\n",
        "    for dirpath, dirnames, filenames in os.walk(path):\n",
        "        for f in filenames:\n",
        "            fp = os.path.join(dirpath, f)\n",
        "            total_size += os.path.getsize(fp)\n",
        "    return total_size\n",
        "\n",
        "export_dir = \"saved_model_distilbert/saved_model\"\n",
        "\n",
        "size_mb = get_dir_size(export_dir) / (1024 * 1024)\n",
        "\n",
        "print(f\" Kích thước mô hình gốc: {size_mb:.2f} MB\")\n",
        "print(f\" Kích thước INT8: {os.path.getsize('distilbert_log_classifier_int8.tflite') / (1024 * 1024):.2f} MB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tObgK0hZH0i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6679c0e8-8649-40fa-e6e3-3599eb0e2ab9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INT8 Model Inputs: [{'name': 'serving_default_attention_mask:0', 'index': 0, 'shape': array([  1, 128], dtype=int32), 'shape_signature': array([  1, 128], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_input_ids:0', 'index': 1, 'shape': array([  1, 128], dtype=int32), 'shape_signature': array([  1, 128], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
          ]
        }
      ],
      "source": [
        "# Load mô hình TFLite đã lượng tử hóa\n",
        "interpreter_int8 = tf.lite.Interpreter(model_path=\"distilbert_log_classifier_int8.tflite\")\n",
        "\n",
        "# Kiểm tra thông tin mô hình\n",
        "print(\"INT8 Model Inputs:\", interpreter_int8.get_input_details())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkI7VUhCWfcO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a7b3c90-354e-43d6-938c-7adc8b7aaa16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1']\n"
          ]
        }
      ],
      "source": [
        "print(os.listdir(\"saved_model_distilbert/saved_model\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyA2bbmBh7is",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f116887c-620b-4e72-8920-eae5678e0c24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tệp INT8 tồn tại: True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "print(\"Tệp INT8 tồn tại:\", os.path.exists(\"distilbert_log_classifier_int8.tflite\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_message = \"System overheating detected. Shutting down in 5 seconds\"\n",
        "\n",
        "input = tokenizer(log_message, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "input = {key: val.to(device) for key, val in input.items()}\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**input)\n",
        "    predicted_label = torch.argmax(outputs.logits, dim=1).cpu().item()\n",
        "\n",
        "decoded_label = label_encoder.classes_[[predicted_label]]\n",
        "\n",
        "print(f\" Log: {log_message}\")\n",
        "print(f\" Cảnh báo dự đoán: {decoded_label}\")"
      ],
      "metadata": {
        "id": "5HSvhGea48T3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "56b6e36e-49c7-4789-d824-0e69fdf6ee56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-ef9a26f3bd94>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mpredicted_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/core/function/polymorphism/function_type.py\u001b[0m in \u001b[0;36mcanonicalize_to_monomorphic\u001b[0;34m(args, kwargs, default_values, capture_types, polymorphic_type)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m       parameters.append(\n\u001b[0;32m--> 583\u001b[0;31m           _make_validated_mono_param(name, arg, poly_parameter.kind,\n\u001b[0m\u001b[1;32m    584\u001b[0m                                      \u001b[0mtype_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m                                      poly_parameter.type_constraint))\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/core/function/polymorphism/function_type.py\u001b[0m in \u001b[0;36m_make_validated_mono_param\u001b[0;34m(name, value, kind, type_context, poly_type)\u001b[0m\n\u001b[1;32m    520\u001b[0m ) -> Parameter:\n\u001b[1;32m    521\u001b[0m   \u001b[0;34m\"\"\"Generates and validates a parameter for Monomorphic FunctionType.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m   \u001b[0mmono_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpoly_type\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmono_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_subtype_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoly_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/core/function/trace_type/trace_type_builder.py\u001b[0m in \u001b[0;36mfrom_value\u001b[0;34m(value, context)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_np_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0mndarray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTENSOR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfKHdIhphyD0"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import tensorflow.lite as tflite\n",
        "\n",
        "# Load mô hình INT8\n",
        "interpreter_int8 = tflite.Interpreter(model_path=\"distilbert_log_classifier_int8.tflite\")\n",
        "interpreter_int8.allocate_tensors()\n",
        "\n",
        "\n",
        "# Chuẩn bị dữ liệu test (có thể lấy từ logs thực tế)\n",
        "test_input = {\n",
        "    \"attention_mask\": np.ones((1, 128), dtype=np.int32),\n",
        "    \"input_ids\": np.random.randint(0, 30522, size=(1, 128), dtype=np.int32)\n",
        "}\n",
        "\n",
        "def run_inference(interpreter, test_input):\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    for i, key in enumerate(test_input.keys()):\n",
        "        interpreter.set_tensor(input_details[i]['index'], test_input[key])\n",
        "\n",
        "    start_time = time.time()\n",
        "    interpreter.invoke()\n",
        "    end_time = time.time()\n",
        "\n",
        "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "    return output_data, end_time - start_time\n",
        "\n",
        "# Chạy inference và đo thời gian\n",
        "output_int8, time_int8 = run_inference(interpreter_int8, test_input)\n",
        "\n",
        "print(f\"Output INT8: {output_int8}, Time: {time_int8:.4f}s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbG1vBoBieXb"
      },
      "outputs": [],
      "source": [
        "threshold = 50  # Với INT8, giá trị nằm trong khoảng [-128, 127] nên chọn ngưỡng cao hơn\n",
        "\n",
        "log_labels_example = [\n",
        "    \"ERROR - MPD problem\", \"ERROR - control amplifier\",\n",
        "    \"ERROR - delete message\", \"ERROR - download message\",\n",
        "    \"ERROR - invalid checksum\", \"ERROR - invalid message size\",\n",
        "    \"ERROR - message download\", \"ERROR - start MPD failed\",\n",
        "    \"ERROR: config SIM, GSM error\", \"NOTE - all threads closed\",\n",
        "    \"NOTE - speaker changes state from Off to On\",\n",
        "    \"NOTE - speaker changes state from On to Off\",\n",
        "    \"Normal\",\n",
        "    \"Note - message played done\", \"UNKNOWN LOG\", \"WARNING - On disconnect\"\n",
        "]\n",
        "\n",
        "labels_int8 = [log_labels_example[i] for i in range(len(output_int8[0])) if output_int8[0][i] > threshold]\n",
        "\n",
        "\n",
        "\n",
        "print(f\" Cảnh báo INT8: {', '.join(labels_int8) if labels_int8 else 'Không có lỗi'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWi6IrO_Dljl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "logs_df = pd.read_csv(\"/content/labeled_logs.csv\")\n",
        "print(\"Các cột trong CSV:\", logs_df.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmaPyny0a4Yh"
      },
      "outputs": [],
      "source": [
        "print(logs_df[\"logs\"].head())\n",
        "print(logs_df[\"logs\"].dtype)  # Kiểm tra kiểu dữ liệu của cột logs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PK1aHTVdCrdu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow.lite as tflite\n",
        "from transformers import DistilBertTokenizer\n",
        "\n",
        "# ======== BƯỚC 1: Load file logs.csv ========\n",
        "log_file = \"/content/labeled_logs.csv\"\n",
        "try:\n",
        "    logs_df = pd.read_csv(log_file)\n",
        "    assert \"logs\" in logs_df.columns, \" Cột 'logs' không tồn tại trong file CSV!\"\n",
        "\n",
        "    # Chuyển tất cả giá trị về chuỗi, thay NaN bằng chuỗi rỗng\n",
        "    logs_df[\"logs\"] = logs_df[\"logs\"].fillna(\"\").astype(str)\n",
        "except Exception as e:\n",
        "    raise SystemExit(f\" Lỗi khi đọc file CSV: {e}\")\n",
        "\n",
        "# ======== BƯỚC 2: Tokenizer thật ========\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "def tokenize_log(log_message):\n",
        "    try:\n",
        "        tokens = tokenizer(\n",
        "            log_message, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"np\"\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": tokens[\"input_ids\"].astype(np.int32),\n",
        "            \"attention_mask\": tokens[\"attention_mask\"].astype(np.int32)\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Lỗi khi tokenize log: {log_message} → {e}\")\n",
        "        return {\n",
        "            \"input_ids\": np.zeros((1, 128), dtype=np.int32),\n",
        "            \"attention_mask\": np.zeros((1, 128), dtype=np.int32)\n",
        "        }\n",
        "\n",
        "logs_data = [tokenize_log(msg) for msg in logs_df[\"logs\"]]\n",
        "\n",
        "# ======== BƯỚC 3: Load mô hình INT8 ========\n",
        "try:\n",
        "    interpreter_int8 = tflite.Interpreter(model_path=\"distilbert_log_classifier_int8.tflite\")\n",
        "\n",
        "\n",
        "    interpreter_int8.allocate_tensors()\n",
        "\n",
        "except Exception as e:\n",
        "    raise SystemExit(f\" Lỗi khi load mô hình: {e}\")\n",
        "\n",
        "# ======== BƯỚC 4: Mapping số nhãn → nội dung cảnh báo ========\n",
        "log_labels_mapping = {\n",
        "    0: \"ERROR - MPD problem\", 1: \"ERROR - control amplifier\",\n",
        "    2: \"ERROR - delete message\", 3: \"ERROR - download message\",\n",
        "    4: \"ERROR - invalid checksum\", 5: \"ERROR - invalid message size\",\n",
        "    6: \"ERROR - message download\", 7: \"ERROR - start MPD failed\",\n",
        "    8: \"ERROR: config SIM, GSM error\", 9: \"NOTE - all threads closed\",\n",
        "    10: \"NOTE - speaker changes state from Off to On\",\n",
        "    11: \"NOTE - speaker changes state from On to Off\",\n",
        "    12: \"Normal\",\n",
        "    13: \"Note - message played done\", 14: \"UNKNOWN LOG\", 15: \"WARNING - On disconnect\"\n",
        "}\n",
        "\n",
        "# ======== BƯỚC 5: Chạy inference ========\n",
        "def run_inference(interpreter, log_data):\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    interpreter.set_tensor(input_details[0]['index'], log_data[\"input_ids\"])\n",
        "    interpreter.set_tensor(input_details[1]['index'], log_data[\"attention_mask\"])\n",
        "    interpreter.invoke()\n",
        "\n",
        "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "    return output_data\n",
        "\n",
        "for i, log_data in enumerate(logs_data):\n",
        "    output_int8 = run_inference(interpreter_int8, log_data)\n",
        "\n",
        "    predicted_label_int8 = np.argmax(output_int8)\n",
        "\n",
        "    # Tránh lỗi KeyError khi tra cứu nhãn\n",
        "    label_int8 = log_labels_mapping.get(predicted_label_int8, \"Unknown label\")\n",
        "\n",
        "    print(f\"Log {i+1}: {logs_df['logs'][i]}\")\n",
        "    print(f\"  - INT8 Prediction: {label_int8}\")\n",
        "    print(\"-\" * 50)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}